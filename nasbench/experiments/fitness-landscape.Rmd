```{r setup, include=FALSE}
knitr::opts_chunk$set(dev = 'png')
setwd("/local_home/trao_ka/projects/andres_code/nasbench/experiments/")

library(ggplot2)
library(pastecs)
library(reshape2)
library(GA)
library(lhs)
library(jsonlite)
library(truncnorm)
library(fitdistrplus)
library(gridExtra)
library(e1071)

#load("nasbench_full_landscape.RData")
```


# NAS101 Landscape

```{r, echo=FALSE, eval=False}
# Data loading and preparation
filename <- "full_landscape.json" 

raw_land <- fromJSON(filename)

land.df <- data.frame(matrix(unlist(raw_land[[2]]$encoded), nrow=length(raw_land[[2]]$encoded), byrow=T))
land.df$tr.params <- raw_land[[2]]$tr_params
for(i in 1:length(raw_land[[2]]$fitness)) {
  colnames(raw_land[[2]]$fitness[[i]]) <- paste(colnames(raw_land[[2]]$fitness[[i]]), colnames(raw_land[[2]]$fitness)[i], sep=".")
  land.df <- cbind(land.df, raw_land[[2]]$fitness[[i]])
}

epochs <- paste(colnames(raw_land[[2]]$fitness), collapse = ", ")
encsize <- 17 * (17 -1) / 2

```

Loaded `r nrow(land.df)` architectures, evaluated for `r epochs` epochs. The architectures are encoded using a binary vector of length `r encsize`, that corresponds to the upper triangular part of the adjacency matrix. Note that this adjacency matrix consists of three operations, input and output. The maximum number of nodes in the model is seven (i.e., input, output, and up to five operations), while the maximum number of edges in the graph is nine. Therefore, the full adjacency matrix consists of input, output, and each operation repeated five times, i.e., 17 rows. Thus, the upper triangular (excluding the diagonal) accounts to 17*16/2 = 136 variables.


```{r echo=FALSE}
encsize <- 17 * (17 -1) / 2 
# Calculate the Hamming distance to the optimum
max.test_acc.36 <- max(land.df$test_acc.36)
max.enc.test_acc.36 <- as.matrix(land.df[ land.df$test_acc.36 == max.test_acc.36, 1:encsize])
hamming.dist.ta.36 <- sapply( 1:nrow(land.df), function(i) {
  dist <- hamming.distance(rbind(max.enc.test_acc.36, as.matrix(land.df[i, 1:encsize])))
  dist[nrow(dist),1:(nrow(dist)-1)]
})

encsize <- 17 * (17 -1) /2 
# Calculate the Hamming distance to the optimum
max.test_acc.108 <- max(land.df$test_acc.108)
max.enc.test_acc.108 <- as.matrix(land.df[ land.df$test_acc.108 == max.test_acc.108, 1:encsize])
hamming.dist.ta.108 <- sapply( 1:nrow(land.df), function(i) {
  dist <- hamming.distance(rbind(max.enc.test_acc.108, as.matrix(land.df[i, 1:encsize])))
  dist[nrow(dist),1:(nrow(dist)-1)]
})

land.df$hamming.dist.max.ta.36 <- hamming.dist.ta.36
land.df$hamming.dist.max.ta.108 <- hamming.dist.ta.108

rm(raw_land, filename, i, hamming.dist.ta.36, max.test_acc.36, max.enc.test_acc.36, hamming.dist.ta.108, max.test_acc.108, max.enc.test_acc.108)

```


## Architectures overview

First, let's have a look into the training times, and to the relation between the training time and the number of trainable parameters...

```{r echo=FALSE}

p1 <- ggplot(land.df) 
#p1 <- p1 + geom_density(aes(x=training_time.4, color="1"))
#p1 <- p1 + geom_density(aes(x=training_time.12, color="2"))
p1 <- p1 + geom_density(aes(x=training_time.36, color="3"))
#p1 <- p1 + geom_density(aes(x=training_time.108, color="4"))
p1 <- p1 + xlab("Training time")
p1 <- p1 + scale_color_manual(values=c("violet", "blue", "green", "red"), labels=c("4", "12", "36", "108"))
p1 <- p1 + labs(color="Epochs")
p1 <- p1 + theme_bw()

p2 <- ggplot(land.df, aes(x=tr.params)) 
#p2 <- p2 + geom_point(aes(y=training_time.4, color="1"))
#p2 <- p2 + geom_point(aes(y=training_time.12, color="2")) 
p2 <- p2 + geom_point(aes(y=training_time.36, color="3")) 
#p2 <- p2 + geom_point(aes(y=training_time.108, color="4"))
p2 <- p2 + xlab("Trainable parameters")
p2 <- p2 + ylab("Training time")
p2 <- p2 + scale_color_manual(values=c("violet", "blue", "green", "red"), labels=c("4", "12", "36", "108"))
p2 <- p2 + labs(color="Epochs")
p2 <- p2 + theme_bw()
 grid.arrange(p1, p2, ncol=2, nrow=1)
```

```{r echo=FALSE}
p1
```

```{r echo=FALSE}
p2
```


## Fitness landscape density distribution

To dig into the fitness landscape, first, we will study the distribution of the fitness.

This is how it looks on train data.

```{r echo=FALSE}
min_acc <- min(land.df[,grep("acc", colnames(land.df), value=TRUE)])


# Densities
p1 <- ggplot(land.df) 
p1 <- p1 + geom_density(aes(x=train_acc.4))
p1 <- p1 + xlab("Train accuracy 4 epochs")
p1 <- p1 + xlim(c(min_acc, 1))
p1 <- p1 + theme_bw()

p2 <- ggplot(land.df) 
p2 <- p2 + geom_density(aes(x=train_acc.12))
p2 <- p2 + xlab("Train accuracy 12 epochs")
p2 <- p2 + xlim(c(min_acc, 1))
p2 <- p2 + theme_bw()

p3 <- ggplot(land.df) 
p3 <- p3 + geom_density(aes(x=train_acc.4))
p3 <- p3 + xlab("Train accuracy 36 epochs")
p3 <- p3 + xlim(c(min_acc, 1))
p3 <- p3 + theme_bw()


p4 <- ggplot(land.df) 
p4 <- p4 + geom_density(aes(x=train_acc.108))
p4 <- p4 + xlab("Train accuracy 108 epochs")
p4 <- p4 + xlim(c(min_acc, 1))
p4 <- p4 + theme_bw()

grid.arrange(p1, p2, p3, p4, ncol=2, nrow=2)
```

Now, on validation data:

```{r echo=FALSE}
p1 <- ggplot(land.df) 
p1 <- p1 + geom_density(aes(x=validation_acc.4))
p1 <- p1 + xlab("Validation accuracy 4 epochs")
p1 <- p1 + xlim(c(min_acc, 1))
p1 <- p1 + theme_bw()

p2 <- ggplot(land.df) 
p2 <- p2 + geom_density(aes(x=validation_acc.12))
p2 <- p2 + xlab("Validation accuracy 12 epochs")
p2 <- p2 + xlim(c(min_acc, 1))
p2 <- p2 + theme_bw()

p3 <- ggplot(land.df) 
p3 <- p3 + geom_density(aes(x=validation_acc.36))
p3 <- p3 + xlab("Validation accuracy 36 epochs")
p3 <- p3 + xlim(c(min_acc, 1))
p3 <- p3 + theme_bw()

p4 <- ggplot(land.df) 
p4 <- p4 + geom_density(aes(x=validation_acc.108))
p4 <- p4 + xlab("Validation accuracy 108 epochs")
p4 <- p4 + xlim(c(min_acc, 1))
p4 <- p4 + theme_bw()

grid.arrange(p1, p2, p3, p4, ncol=2, nrow=2)
```

And on test data:

```{r echo=FALSE}

p1 <- ggplot(land.df, cex.main=3, cex.lab=3, cex.axis=3, lwd=2)
p1 <- p1 + geom_density(aes(x=test_acc.4), lwd=1.5)
p1 <- p1 + xlab("Test accuracy 4 epochs")
p1 <- p1 + xlim(c(min_acc, 1))
p1 <- p1 + theme_bw()

p2 <- ggplot(land.df, cex.main=3, cex.lab=3, cex.axis=3, lwd=2)
p2 <- p2 + geom_density(aes(x=test_acc.12), lwd=1.5)
p2 <- p2 + xlab("Test accuracy 12 epochs")
p2 <- p2 + xlim(c(min_acc, 1))
p2 <- p2 + theme_bw()

p3 <- ggplot(land.df, cex.main=3, cex.lab=3, cex.axis=3, lwd=2)
p3 <- p3 + geom_density(aes(x=test_acc.36), lwd=1.5)
p3 <- p3 + xlab("Test accuracy 36 epochs")
p3 <- p3 + xlim(c(min_acc, 1))
p3 <- p3 + theme_bw()

p4 <- ggplot(land.df, cex.main=3, cex.lab=3, cex.axis=3, lwd=2)
p4 <- p4 + geom_density(aes(x=test_acc.108), lwd=1.5)
p4 <- p4 + xlab("Test accuracy 108 epochs")
p4 <- p4 + xlim(c(min_acc, 1))
p4 <- p4 + theme_bw()

grid.arrange(p1, p2, p3, p4, ncol=2, nrow=2)
```


Now, let's have a look into the the relation between the accuracy and the number of trainable parameters:

```{r echo=FALSE}
p1 <- ggplot(land.df, aes(x=test_acc.4, y=tr.params)) 
p1 <- p1 + geom_point()
p1 <- p1 + xlab("Test accuracy 4 epochs")
p1 <- p1 + ylab("Trainable parameters")
p1 <- p1 + xlim(c(min_acc, 1))
p1 <- p1 + theme_bw()
p1 <- p1 + geom_smooth(method='lm', formula=y~x)

p2 <- ggplot(land.df, aes(x=test_acc.12, y=tr.params)) 
p2 <- p2 + geom_point()
p2 <- p2 + xlab("Test accuracy 12 epochs")
p2 <- p2 + ylab("Trainable parameters")
p2 <- p2 + xlim(c(min_acc, 1))
p2 <- p2 + theme_bw()
p2 <- p2 + geom_smooth(method='lm', formula=y~x)

p3 <- ggplot(land.df, aes(x=test_acc.36, y=tr.params)) 
p3 <- p3 + geom_point()
p3 <- p3 + xlab("Test accuracy 36 epochs")
p3 <- p3 + ylab("Trainable parameters")
p3 <- p3 + xlim(c(min_acc, 1))
p3 <- p3 + theme_bw()
p3 <- p3 + geom_smooth(method='lm', formula=y~x)

p4 <- ggplot(land.df, aes(x=test_acc.108, y=tr.params)) 
p4 <- p4 + geom_point()
p4 <- p4 + xlab("Test accuracy 108 epochs")
p4 <- p4 + ylab("Trainable parameters")
p4 <- p4 + xlim(c(min_acc, 1))
p4 <- p4 + theme_bw()
p4 <- p4 + geom_smooth(method='lm', formula=y~x)

grid.arrange(p1, p2, p3, p4, ncol=2, nrow=2)
```


Can we model the density of the fitness using a PDF? Considering the test accuracy on 36 epochs:

```{r echo=FALSE}
fb <- fitdist(land.df$validation_acc.36, "beta")
summary(fb)

fw <- fitdist(land.df$validation_acc.36, "weibull")
summary(fw)

fl <- fitdist(land.df$validation_acc.36, "lnorm")
summary(fl)

par(mfrow = c(2, 2))
plot.legend <- c("Beta", "Weibull", "Lognormal")
p1 <- denscomp(list(fb, fw, fl), legendtext = plot.legend)
p2 <- qqcomp(list(fb, fw, fl), legendtext = plot.legend)
p3 <- cdfcomp(list(fb, fw, fl), legendtext = plot.legend)
p4 <- ppcomp(list(fb, fw, fl), legendtext = plot.legend)
grid.arrange(p1, p2, p3, p4, ncol=2, nrow=2)
p1
```


And on 108 epochs:

```{r echo=FALSE}
fb <- fitdist(land.df$validation_acc.108, "beta")
summary(fb)

fw <- fitdist(land.df$validation_acc.108, "weibull")
summary(fw)

fl <- fitdist(land.df$validation_acc.108, "lnorm")
summary(fl)

par(mfrow = c(2, 2))
plot.legend <- c("Beta", "Weibull", "Lognormal")
p1 <- denscomp(list(fb, fw, fl), legendtext = plot.legend)
p2 <- qqcomp(list(fb, fw, fl), legendtext = plot.legend)
p3 <- cdfcomp(list(fb, fw, fl), legendtext = plot.legend)
p4 <- ppcomp(list(fb, fw, fl), legendtext = plot.legend)
grid.arrange(p1, p2, p3, p4, ncol=2, nrow=2)

```

## Landscape topology

To analyze the topology of the landscape, we calculated the hamming distance from each solution to the maximum test accuracy on 36 and 108 epochs.

```{r echo=FALSE}

p0 <- ggplot(land.df)
p0 <- p0 + geom_histogram(aes(x=hamming.dist.max.ta.36, fill="1"), binwidth = 1, alpha=0.5, position="identity")
p0 <- p0 + geom_histogram(aes(x=hamming.dist.max.ta.108, fill="2"), binwidth = 1, alpha=0.5, position="identity")
p0 <- p0 + scale_fill_manual(values=c("green", "red"), labels=c("36", "108"))
p0 <- p0 + xlab("Hamming distance to the maximum")
p0 <- p0 + labs(fill="Epochs")
p0 <- p0 + theme_bw() #+ theme(text = element_text(size = 35))
# cor.ha.ta.108 <- cor.test(land.df$hamming.dist.max.ta.108, land.df$kappaCohen_test.108)

p1 <- ggplot(land.df)
p1 <- p1 + geom_point(aes(x=hamming.dist.max.ta.36, y=test_acc.36, color="1"), alpha=0.2)
p1 <- p1 + geom_smooth(aes(x=hamming.dist.max.ta.36, y=test_acc.36, color="1"), method='lm', formula=y~x)
p1 <- p1 + geom_point(aes(x=hamming.dist.max.ta.108, y=test_acc.108, color="2"), alpha=0.2)
p1 <- p1 + geom_smooth(aes(x=hamming.dist.max.ta.108, y=test_acc.108, color="2"), method='lm', formula=y~x)
p1 <- p1 + scale_color_manual(values=c("green", "red"), labels=c("36", "108"))
p1 <- p1 + xlab("Hamming distance to the maximum")
p1 <- p1 + ylab("Test accuracy")
p1 <- p1 + labs(color="Epochs")
p1 <- p1 + theme_bw() #+ theme(text = element_text(size = 35))

p2 <- ggplot(land.df, aes(x=as.factor(hamming.dist.max.ta.36)))
p2 <- p2 + geom_boxplot(aes(y=test_acc.36))
p2 <- p2 + xlab("Hamming distance to the optimum")
p2 <- p2 + ylab("Test accuracy 36 epochs")
p2 <- p2 + theme_bw() #+ theme(text = element_text(size = 35))

p3 <- ggplot(land.df, aes(x=as.factor(hamming.dist.max.ta.108)))
p3 <- p3 + geom_boxplot(aes(y=test_acc.108))
p3 <- p3 + xlab("Hamming distance to the optimum")
p3 <- p3 + ylab("Test accuracy 108 epochs")
p3 <- p3 + theme_bw()# + theme(text = element_text(size = 35))

grid.arrange(p0, p1, p2, p3, ncol=2, nrow=2)
```


Then, we performed 30 independent random walks.
Please uncomment for run & analysis
```{r echo=FALSE, eval=FALSE}

# randomWalk <- function(search_space, metric, start_point=1, length=10) {
#   fitness_walk <- data.frame(path=c(start_point), fitness=c(metric[start_point]))
#   for(i in 1:(length-1)) {
#     while(TRUE) {
#       step <- sample(nrow(search_space), 1)
#       current <- fitness_walk[nrow(fitness_walk),1]
#       if( hamming.distance(as.matrix(search_space[c(current,step),]))[2,1] == 1 ) {
#         fitness_walk <- rbind(fitness_walk, data.frame(path=c(step), fitness=c(metric[step])))
#         break
#       }
#     }
#   }
#   fitness_walk$step <- 1:length
#   return(fitness_walk)
# }
# 
# parallelRandomWalk <- function(search_space, metric, start_points, max_steps) {
#   fitness_walk <- data.frame(path=start_points)
#   fitness_walk$fitness <- metric[start_points]
#   fitness_walk$step <- 1
#   fitness_walk$route <- 1:length(start_points)
#   current_position <- fitness_walk[,c("route", "path", "step")]
#   while(TRUE) {
#     solution <- sample(nrow(search_space), 1000)
#     distances <- hamming.distance(as.matrix(search_space[c(current_position$path, solution),]))
#     pos <- which(distances == 1, arr.ind=TRUE)
#     # filter the paths starting from the new solutions or going to the current paths
#     pos <- pos[which(pos[, c("row")] <= nrow(current_position) & pos[, c("col")] > nrow(current_position)), , drop=FALSE]
#     if( length(pos) > 0 ) {
#       del_list <- c()
#       visited <- c()
#       for(i in 1:nrow(pos)) {
#         if( is.na( match(pos[i,1], visited) ) ) {
#           visited <- c(visited, pos[i,1])
#           .step <- current_position[pos[i,1], c("step")] + 1
#           .route <- current_position[pos[i,1], c("route")]
#           .path <- as.numeric(colnames(distances)[pos[i,2]])
#           fitness_walk <- rbind(fitness_walk, data.frame(path=.path, step=.step, route=.route, fitness=metric[.path]))
#           if(.step < max_steps) {  
#             current_position[pos[i,1], c("step")] <- .step
#             current_position[pos[i,1], c("path")] <- .path
#             print(paste("route", .route, "step", .step, sep=" "))
#           } else {
#             del_list <- c(del_list, pos[i,1])
#           }
#         }
#       }
#       if(length(del_list) > 0) {
#         current_position <- current_position[-del_list,]
#       }
#     }
#     if(nrow(current_position) == 0) {
#       break
#     }
#   }
#   return(fitness_walk)
# }
# 
# metric_name <- c("validation_acc.36")
# start_points <- sample(nrow(land.df), 30)
# 
# fitness_walk <- parallelRandomWalk(land.df[, 1:encsize], land.df[, metric_name], start_points, 100)
# 
# #for(i in 1:length(start_points)) {
# #  f_w <- randomWalk(land.df[, 1:encsize], land.df[, metric_name], start_point = 1, length = 100)
# #  f_w$route <- i
# #  fitness_walk <- rbind(fitness_walk, f_w)
# #}
# #stat.desc(land.df[, metric_name])

```

```{r echo=FALSE}

# p <- ggplot(fitness_walk, aes(x=step, y=fitness, group=route, color=as.factor(route)))
# p <- p + geom_line()
# p <- p + xlab("Random walk step") + ylab("Validation accuracy")
# p <- p + geom_hline(yintercept=max(land.df[, metric_name]), linetype="dashed", color = "red")
# p <- p + labs(color="Route")
# p <- p + ylim(c(min_acc, 1))
# p <- p + theme_bw()
# p
# 
# p <- ggplot(fitness_walk, aes(x=as.factor(route), y=fitness))
# p <- p + geom_boxplot()
# p <- p + xlab("Random walk route") + ylab("Validation accuracy")
# p <- p + geom_hline(yintercept=max(land.df[, metric_name]), linetype="dashed", color = "red")
# p <- p + ylim(c(min_acc, 1))
# p <- p + theme_bw()
# p

```


## Sampling approximation

```{r echo=FALSE}
 samp_sizes <- c(10, 100, 1000, 10000)
 
 p <- ggplot()
 for(i in samp_sizes) {
   pos <- sample(nrow(land.df), i)
   p <- p + geom_density(data=land.df[pos, ], aes(x=validation_acc.36, color=as.factor(!!i)), lwd=1.5)
 }
 p <- p + xlim(c(min_acc, 1))
 p <- p + theme_bw()
 p <- p + xlab("Fitness (36 epochs)") + labs(color="Sample size") + theme(text = element_text(size = 40))
 p

```
