{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDOE import *\n",
    "import matplotlib.pyplot as plt# Standard imports\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns \n",
    "\n",
    "# Fixing random state for reproducibility\n",
    "np.random.seed(19680801)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study of Robustness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_home/trao_ka/anaconda3/envs/nas_benchmarks/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/local_home/trao_ka/anaconda3/envs/nas_benchmarks/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/local_home/trao_ka/anaconda3/envs/nas_benchmarks/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/local_home/trao_ka/anaconda3/envs/nas_benchmarks/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/local_home/trao_ka/anaconda3/envs/nas_benchmarks/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/local_home/trao_ka/anaconda3/envs/nas_benchmarks/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /local_home/trao_ka/projects/nasbench/nasbench/lib/training_time.py:130: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "WARNING:tensorflow:From /local_home/trao_ka/projects/nasbench/nasbench/lib/training_time.py:174: The name tf.train.CheckpointSaverListener is deprecated. Please use tf.estimator.CheckpointSaverListener instead.\n",
      "\n",
      "WARNING:tensorflow:From /local_home/trao_ka/projects/nasbench/nasbench/lib/evaluate.py:33: The name tf.train.NanLossDuringTrainingError is deprecated. Please use tf.estimator.NanLossDuringTrainingError instead.\n",
      "\n",
      "Loading dataset from file... This may take a few minutes...\n",
      "WARNING:tensorflow:From /local_home/trao_ka/projects/nasbench/nasbench/api.py:151: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_home/trao_ka/anaconda3/envs/nas_benchmarks/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/local_home/trao_ka/anaconda3/envs/nas_benchmarks/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/local_home/trao_ka/anaconda3/envs/nas_benchmarks/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/local_home/trao_ka/anaconda3/envs/nas_benchmarks/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/local_home/trao_ka/anaconda3/envs/nas_benchmarks/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/local_home/trao_ka/anaconda3/envs/nas_benchmarks/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset in 161 seconds\n"
     ]
    }
   ],
   "source": [
    "# Initialize the NASBench object which parses the raw data into memory (this\n",
    "# should only be run once as it takes up to a few minutes).\n",
    "from nasbench import api\n",
    "\n",
    "path_to_nasbench_data_full ='/local_home/trao_ka/data/nasbench_full.tfrecord'\n",
    "#path_to_nasbench_data_full = '/media/kalifou/SAMSUNG1/DLR_DAAD_Research_Backup/data/nasbench_full.tfrecord'\n",
    "\n",
    "# Use nasbench_full.tfrecord for full dataset (run download command above).\n",
    "nasbench = api.NASBench(path_to_nasbench_data_full)\n",
    "#('/home/kalifou/Documents/dlr/data/nasbench_full.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Useful constants\n",
    "INPUT = 'input'\n",
    "OUTPUT = 'output'\n",
    "CONV3X3 = 'conv3x3-bn-relu'\n",
    "CONV1X1 = 'conv1x1-bn-relu'\n",
    "MAXPOOL3X3 = 'maxpool3x3'\n",
    "NUM_VERTICES = 7\n",
    "MAX_EDGES = 9\n",
    "EDGE_SPOTS = NUM_VERTICES * (NUM_VERTICES - 1) / 2   # Upper triangular matrix\n",
    "OP_SPOTS = NUM_VERTICES - 2   # Input/output vertices are fixed\n",
    "ALLOWED_OPS = [CONV3X3, CONV1X1, MAXPOOL3X3]\n",
    "ALLOWED_EDGES = [0, 1]   # Binary adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_single_op(NUM_VERTICES, ALLOWED_OPS):\n",
    "    x = lhs(NUM_VERTICES, samples=1)[0]\n",
    "    vv = np.floor(x * len(ALLOWED_OPS))\n",
    "    op  = [ALLOWED_OPS[int(k)] for k in vv]\n",
    "    op[0] = INPUT\n",
    "    op[-1] = OUTPUT\n",
    "    return op\n",
    "\n",
    "def sample_single_configurations_lhs(N_dimensions):    \n",
    "    \n",
    "    sum_edges = 0   \n",
    "    while sum_edges != 9:\n",
    "        v_m = lhs(N_dimensions, samples=1)\n",
    "        idx = v_m > 0.5\n",
    "        v_m[idx == True] = 1\n",
    "        v_m[idx == False] = 0\n",
    "        sum_edges = sum(v_m[0])\n",
    "    \n",
    "    return v_m[0]\n",
    "\n",
    "def recover_incidence_matrix(a0, N_l=7):\n",
    "    \n",
    "    mat = np.zeros((N_l, N_l))\n",
    "    idx_new = 0\n",
    "    idx_old = 0\n",
    "    \n",
    "    for i in range(N_l):\n",
    "        idx_new += N_l - i - 1\n",
    "        \n",
    "        values = a0[idx_old:idx_new]\n",
    "        idx_old = idx_new\n",
    "        mat[i, i+1: ] = values\n",
    "        \n",
    "    return mat\n",
    "\n",
    "def sample_single_valid_spec(NUM_vert, allowed_ops):\n",
    "    \n",
    "    is_valid = False\n",
    "    while not is_valid:\n",
    "        current_op = sample_single_op(NUM_vert, allowed_ops)\n",
    "        current_config = sample_single_configurations_lhs(N_dimensions = 7 * 3) \n",
    "        current_mat = recover_incidence_matrix(current_config, N_l=NUM_vert)\n",
    "        current_spec = api.ModelSpec(matrix=current_mat, ops=current_op)        \n",
    "        is_valid = nasbench.is_valid(current_spec)\n",
    "        \n",
    "    return current_mat, current_op, current_spec\n",
    "\n",
    "def LHS_sample_N_valid_specs(N, NUM_vert, allowed_ops, nb):\n",
    " all_specs = []\n",
    " set_mats = set()\n",
    " while len(set_mats) < N:\n",
    "   s = sample_single_valid_spec(NUM_vert, allowed_ops)\n",
    "   m, o, sp = s\n",
    "   t_m = tuple(m.reshape(NUM_vert * NUM_vert))\n",
    "   hash_m = nb._hash_spec(sp)\n",
    "   if hash_m not in set_mats:\n",
    "     set_mats = set_mats | set([t_m])\n",
    "     all_specs.append(s)\n",
    "\n",
    " return all_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_spec():\n",
    "  \"\"\"Returns a random valid spec.\"\"\"\n",
    "  while True:\n",
    "    matrix = np.random.choice(ALLOWED_EDGES, size=(NUM_VERTICES, NUM_VERTICES))\n",
    "    matrix = np.triu(matrix, 1)\n",
    "    ops = np.random.choice(ALLOWED_OPS, size=(NUM_VERTICES)).tolist()\n",
    "    ops[0] = INPUT\n",
    "    ops[-1] = OUTPUT\n",
    "    spec = api.ModelSpec(matrix=matrix, ops=ops)\n",
    "    if nasbench.is_valid(spec):\n",
    "      return matrix, ops, spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#N_samples = 10000\n",
    "#N_samples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra_specs = LHS_sample_N_valid_specs(N_samples, 7, ALLOWED_OPS, nasbench)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_samples = 10000\n",
    "extra_specs = list()\n",
    "for iter in range(N_samples):\n",
    "    spec = random_spec()\n",
    "    extra_specs.append(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_epochs = 4\n",
    "all_data_4_cf10 = list()\n",
    "for m, o, cell in extra_specs:\n",
    "    # Query an Inception-like cell from the dataset.\n",
    "    cell = api.ModelSpec(\n",
    "      matrix= m.astype(int),\n",
    "      # Operations at the vertices of the module, matches order of matrix.\n",
    "      ops= o) #[INPUT, CONV1X1, CONV3X3, CONV3X3, CONV3X3, MAXPOOL3X3, OUTPUT])\n",
    "\n",
    "    data = nasbench.query(cell, epochs=N_epochs)\n",
    "    all_data_4_cf10.append((m, o, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_epochs = 12\n",
    "all_data_12_cf10 = list()\n",
    "for m, o, cell in extra_specs:\n",
    "    # Query an Inception-like cell from the dataset.\n",
    "    cell = api.ModelSpec(\n",
    "      matrix= m.astype(int),\n",
    "      # Operations at the vertices of the module, matches order of matrix.\n",
    "      ops= o) #[INPUT, CONV1X1, CONV3X3, CONV3X3, CONV3X3, MAXPOOL3X3, OUTPUT])\n",
    "\n",
    "    data = nasbench.query(cell, epochs=N_epochs)\n",
    "    all_data_12_cf10.append((m, o, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_epochs = 36\n",
    "all_data_36_cf10 = list()\n",
    "for m, o, cell in extra_specs:\n",
    "    # Query an Inception-like cell from the dataset.\n",
    "    cell = api.ModelSpec(\n",
    "      matrix= m.astype(int),\n",
    "      # Operations at the vertices of the module, matches order of matrix.\n",
    "      ops= o) #[INPUT, CONV1X1, CONV3X3, CONV3X3, CONV3X3, MAXPOOL3X3, OUTPUT])\n",
    "\n",
    "    data = nasbench.query(cell, epochs=N_epochs)\n",
    "    all_data_36_cf10.append((m, o, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_epochs = 108\n",
    "all_data_108_cf10 = list()\n",
    "for m, o, cell in extra_specs:\n",
    "    # Query an Inception-like cell from the dataset.\n",
    "    cell = api.ModelSpec(\n",
    "      matrix= m.astype(int),\n",
    "      # Operations at the vertices of the module, matches order of matrix.\n",
    "      ops= o) #[INPUT, CONV1X1, CONV3X3, CONV3X3, CONV3X3, MAXPOOL3X3, OUTPUT])\n",
    "\n",
    "    data = nasbench.query(cell, epochs=N_epochs)\n",
    "    all_data_108_cf10.append((m, o, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness across regimes : CIFAR-10\n",
    "\n",
    "## Top-N%: \n",
    "### Absolute TOP-N%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_local(values_, N=100, key='test_accuracy'):\n",
    "    s_key = sorted(values_, key= lambda triplet: triplet[2][key]) \n",
    "    top_n_idx = len(s_key) * N/100\n",
    "    top_n_idx = round(top_n_idx)\n",
    "    return s_key[-top_n_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottom_n_local(values_, N=100, key='test_accuracy'):\n",
    "    s_key = sorted(values_, key= lambda triplet: triplet[2][key]) \n",
    "    top_n_idx = len(s_key) * N/100\n",
    "    top_n_idx = round(top_n_idx)\n",
    "    return s_key[:top_n_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_r_04 = top_n_local(all_data_36_cf10, N=10, key='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_min12 = top_n_r_04[0]\n",
    "model_max12 = top_n_r_04[len(top_n_r_04)-1]\n",
    "#print(len(model_min12), len(model_max12))\n",
    "min_ri_test_acc12 = min(model_min12[2]['test_accuracy'], model_max12[2]['test_accuracy'])\n",
    "max_ri_test_acc12 = max(model_min12[2]['test_accuracy'], model_max12[2]['test_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ri_test_acc12, max_ri_test_acc12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative = False\n",
    "size_inter_cifar10_top = []\n",
    "total_size = N_samples\n",
    "\n",
    "for N in range(1, 100 + 1):\n",
    "    #print(N)\n",
    "    top_n_r_04 = top_n_local(all_data_4_cf10, N=N, key='test_accuracy')\n",
    "    top_n_r_12 = top_n_local(all_data_12_cf10, N=N, key='test_accuracy')\n",
    "    top_n_r_36 = top_n_local(all_data_36_cf10, N=N, key='test_accuracy')\n",
    "    top_n_r_108 = top_n_local(all_data_108_cf10, N=N, key='test_accuracy')\n",
    "\n",
    "    top_n_r_4_models = [(m4, o4) for (m4, o4, _) in top_n_r_04]\n",
    "    #top_n_r_12_models = [(m12, o12) for (m12, o12, _) in top_n_r_12]\n",
    "    #top_n_r_36_models = [(m36, o36) for (m36, o36, _) in top_n_r_36]\n",
    "    #top_n_r_108_models = [(m108, o108) for (m108, o108, _) in top_n_r_108]\n",
    "\n",
    "    cross_4_12 = []\n",
    "    cross_4_12_36 = []\n",
    "    cross_all = []\n",
    "    \n",
    "    model_min12 = top_n_r_12[0]\n",
    "    model_max12 = top_n_r_12[len(top_n_r_12)-1]\n",
    "    #print(len(model_min12), len(model_max12))\n",
    "    min_ri_test_acc12 = min(model_min12[2]['test_accuracy'], model_max12[2]['test_accuracy'])\n",
    "    max_ri_test_acc12 = max(model_min12[2]['test_accuracy'], model_max12[2]['test_accuracy'])\n",
    "\n",
    "    for duo_i in top_n_r_04:\n",
    "        # in R = 12 \n",
    "        #for duo_j in top_25_r_12:\n",
    "        #    if np.all(duo_i[0] == duo_j[0]) and np.all(duo_i[1] == duo_j[1]) :\n",
    "        #        cross_4_12.append(duo_i)\n",
    "        cell = api.ModelSpec(\n",
    "          matrix= duo_i[0],\n",
    "          # Operations at the vertices of the module, matches order of matrix.\n",
    "          ops= duo_i[1])\n",
    "        data = nasbench.query(cell, epochs=12)\n",
    "        \n",
    "        if data['test_accuracy'] >= min_ri_test_acc12 and data['test_accuracy'] <= max_ri_test_acc12:\n",
    "            cross_4_12.append(duo_i)\n",
    "        \n",
    "    model_min36 = top_n_r_36[0]\n",
    "    model_max36 = top_n_r_36[len(top_n_r_36)-1]\n",
    "\n",
    "    min_ri_test_acc36 = min(model_min36[2]['test_accuracy'], model_max36[2]['test_accuracy'])\n",
    "    max_ri_test_acc36 = max(model_min36[2]['test_accuracy'], model_max36[2]['test_accuracy'])\n",
    "        \n",
    "    for duo_i in cross_4_12:\n",
    "        # in R = 12 \n",
    "        #for duo_j in top_25_r_36_models:\n",
    "        #    if np.all(duo_i[0] == duo_j[0]) and np.all(duo_i[1] == duo_j[1]) :\n",
    "        #        cross_4_12_36.append(duo_i)\n",
    "        cell = api.ModelSpec(\n",
    "          matrix= duo_i[0],\n",
    "          # Operations at the vertices of the module, matches order of matrix.\n",
    "          ops= duo_i[1])\n",
    "        data = nasbench.query(cell, epochs=36)\n",
    "        \n",
    "        if data['test_accuracy'] >= min_ri_test_acc36 and data['test_accuracy'] <= max_ri_test_acc36:\n",
    "            cross_4_12_36.append(duo_i)\n",
    "            \n",
    "    model_min108 = top_n_r_108[0]\n",
    "    model_max108 = top_n_r_108[len(top_n_r_108)-1]\n",
    "\n",
    "    min_ri_test_acc108 = min(model_min108[2]['test_accuracy'], model_max108[2]['test_accuracy'])\n",
    "    max_ri_test_acc108 = max(model_min108[2]['test_accuracy'], model_max108[2]['test_accuracy'])\n",
    "    \n",
    "    for duo_i in cross_4_12_36:\n",
    "        # in R = 12 \n",
    "        #for duo_j in top_25_r_108:\n",
    "        #    if np.all(duo_i[0] == duo_j[0]) and np.all(duo_i[1] == duo_j[1]) :\n",
    "        #        cross_all.append(duo_i)\n",
    "        \n",
    "        cell = api.ModelSpec(\n",
    "          matrix= duo_i[0],\n",
    "          # Operations at the vertices of the module, matches order of matrix.\n",
    "          ops= duo_i[1])\n",
    "        data = nasbench.query(cell, epochs=108)\n",
    "        \n",
    "        if data['test_accuracy'] >= min_ri_test_acc108 and data['test_accuracy'] <= max_ri_test_acc108:\n",
    "            cross_all.append(duo_i)\n",
    "            \n",
    "    if relative:\n",
    "        len_top_4 = len(top_n_r_04)\n",
    "        assert len_top_4 == N\n",
    "    else:\n",
    "        len_top_4 = total_size\n",
    "\n",
    "    l0, l1, l2, l3 = len(top_n_r_04) / len_top_4, len(cross_4_12)/len_top_4, len(cross_4_12_36)/len_top_4, len(cross_all)/len_top_4\n",
    "    size_inter_cifar10_top.append((l0 * 100, l1 * 100, l2 * 100, l3 * 100))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Failure across time: models remaining Bottom-N% after being Bottom-N% at 4 epochs \\n CIFAR10'\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.ylim(0, 102) #len(mean_perf_half))\n",
    "plt.xlim(0, 100)\n",
    "#plt.set_xticks(5)\n",
    "plt.plot(range(1, 101), [s[0] for s in size_inter_cifar10_top], label = \"Across: [4] epochs (Reference)\",)\n",
    "plt.plot(range(1, 101), [s[1] for s in size_inter_cifar10_top], label = \"Across: [4, 12] epochs\",)\n",
    "plt.plot(range(1, 101), [s[2] for s in size_inter_cifar10_top], label = \"Across: [4, 12, 36] epochs)\",)\n",
    "plt.plot(range(1, 101), [s[3] for s in size_inter_cifar10_top], label = \"Across: [4, 12, 36, 108] epochs\",)\n",
    "plt.title(label=title)\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Bottom-N (in %)')\n",
    "plt.ylabel('Size of intersection (%)')\n",
    "#plt.axvline(x=10, color='red')\n",
    "#plt.axvline(x=25, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density of States of TOP-N Performers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative = False\n",
    "size_inter_cifar10_top = []\n",
    "total_size = N_samples\n",
    "\n",
    "all_final_sets_all_N = list()\n",
    "\n",
    "range_N = range(1, 100 + 1)\n",
    "\n",
    "for N in range_N:\n",
    "    #print(N)\n",
    "    top_n_r_04 = top_n_local(all_data_4_cf10, N=N, key='test_accuracy')\n",
    "    top_n_r_12 = top_n_local(all_data_12_cf10, N=N, key='test_accuracy')\n",
    "    top_n_r_36 = top_n_local(all_data_36_cf10, N=N, key='test_accuracy')\n",
    "    top_n_r_108 = top_n_local(all_data_108_cf10, N=N, key='test_accuracy')\n",
    "\n",
    "    top_n_r_4_models = [(m4, o4) for (m4, o4, _) in top_n_r_04]\n",
    "    #top_n_r_12_models = [(m12, o12) for (m12, o12, _) in top_n_r_12]\n",
    "    #top_n_r_36_models = [(m36, o36) for (m36, o36, _) in top_n_r_36]\n",
    "    #top_n_r_108_models = [(m108, o108) for (m108, o108, _) in top_n_r_108]\n",
    "\n",
    "    cross_4_12 = []\n",
    "    cross_4_12_36 = []\n",
    "    cross_all = []\n",
    "    \n",
    "    model_min12 = top_n_r_12[0]\n",
    "    model_max12 = top_n_r_12[len(top_n_r_12)-1]\n",
    "    #print(len(model_min12), len(model_max12))\n",
    "    min_ri_test_acc12 = min(model_min12[2]['test_accuracy'], model_max12[2]['test_accuracy'])\n",
    "    max_ri_test_acc12 = max(model_min12[2]['test_accuracy'], model_max12[2]['test_accuracy'])\n",
    "\n",
    "    for duo_i in top_n_r_04:\n",
    "        # in R = 12 \n",
    "        #for duo_j in top_25_r_12:\n",
    "        #    if np.all(duo_i[0] == duo_j[0]) and np.all(duo_i[1] == duo_j[1]) :\n",
    "        #        cross_4_12.append(duo_i)\n",
    "        cell = api.ModelSpec(\n",
    "          matrix= duo_i[0],\n",
    "          # Operations at the vertices of the module, matches order of matrix.\n",
    "          ops= duo_i[1])\n",
    "        data = nasbench.query(cell, epochs=12)\n",
    "        \n",
    "        if data['test_accuracy'] >= min_ri_test_acc12 and data['test_accuracy'] <= max_ri_test_acc12:\n",
    "            cross_4_12.append(duo_i)\n",
    "        \n",
    "    model_min36 = top_n_r_36[0]\n",
    "    model_max36 = top_n_r_36[len(top_n_r_36)-1]\n",
    "\n",
    "    min_ri_test_acc36 = min(model_min36[2]['test_accuracy'], model_max36[2]['test_accuracy'])\n",
    "    max_ri_test_acc36 = max(model_min36[2]['test_accuracy'], model_max36[2]['test_accuracy'])\n",
    "        \n",
    "    for duo_i in cross_4_12:\n",
    "        # in R = 12 \n",
    "        #for duo_j in top_25_r_36_models:\n",
    "        #    if np.all(duo_i[0] == duo_j[0]) and np.all(duo_i[1] == duo_j[1]) :\n",
    "        #        cross_4_12_36.append(duo_i)\n",
    "        cell = api.ModelSpec(\n",
    "          matrix= duo_i[0],\n",
    "          # Operations at the vertices of the module, matches order of matrix.\n",
    "          ops= duo_i[1])\n",
    "        data = nasbench.query(cell, epochs=36)\n",
    "        \n",
    "        if data['test_accuracy'] >= min_ri_test_acc36 and data['test_accuracy'] <= max_ri_test_acc36:\n",
    "            cross_4_12_36.append(duo_i)\n",
    "            \n",
    "    model_min108 = top_n_r_108[0]\n",
    "    model_max108 = top_n_r_108[len(top_n_r_108)-1]\n",
    "\n",
    "    min_ri_test_acc108 = min(model_min108[2]['test_accuracy'], model_max108[2]['test_accuracy'])\n",
    "    max_ri_test_acc108 = max(model_min108[2]['test_accuracy'], model_max108[2]['test_accuracy'])\n",
    "    \n",
    "    for duo_i in cross_4_12_36:\n",
    "        # in R = 12 \n",
    "        #for duo_j in top_25_r_108:\n",
    "        #    if np.all(duo_i[0] == duo_j[0]) and np.all(duo_i[1] == duo_j[1]) :\n",
    "        #        cross_all.append(duo_i)\n",
    "        \n",
    "        cell = api.ModelSpec(\n",
    "          matrix= duo_i[0],\n",
    "          # Operations at the vertices of the module, matches order of matrix.\n",
    "          ops= duo_i[1])\n",
    "        data = nasbench.query(cell, epochs=108)\n",
    "        \n",
    "        if data['test_accuracy'] >= min_ri_test_acc108 and data['test_accuracy'] <= max_ri_test_acc108:\n",
    "            cross_all.append(duo_i)\n",
    "    \n",
    "    all_final_sets_all_N.append(cross_all.copy())\n",
    "    \n",
    "    if relative:\n",
    "        len_top_4 = len(top_n_r_04)\n",
    "        assert len_top_4 == N\n",
    "    else:\n",
    "        len_top_4 = total_size\n",
    "\n",
    "    l0, l1, l2, l3 = len(top_n_r_04) / len_top_4, len(cross_4_12)/len_top_4, len(cross_4_12_36)/len_top_4, len(cross_all)/len_top_4\n",
    "    size_inter_cifar10_top.append((l0 * 100, l1 * 100, l2 * 100, l3 * 100))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i, cross_all in enumerate(all_final_sets_all_N[:100]):\n",
    "#    print(i, len(cross_all), len(top_n_r_4_models), len(cross_all)/len(top_n_r_4_models))\n",
    "#print(len(all_final_sets_all_N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_data_top_N = list()\n",
    "#training_budgets = [4, 12, 36, 108]\n",
    "\n",
    "#for tuple_id_model in cross_all:\n",
    "#    local_cell = api.ModelSpec(matrix= tuple_id_model[0],\n",
    "#        # Operations at the vertices of the module, matches order of matrix.\n",
    "#        ops= tuple_id_model[1])#\n",
    "\n",
    "#    local_eval_data = {budget_i:nasbench.query(local_cell, epochs=budget_i) for budget_i in training_budgets} \n",
    "#    all_data_top_N.append( (tuple_id_model[0], tuple_id_model[1], local_eval_data) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i, cross_all in enumerate(all_final_sets_all_N):\n",
    "#    print(i, len(cross_all), len(top_n_r_4_models), len(cross_all)/len(top_n_r_4_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_testAcc_All_regimes_N_ranks = list()\n",
    "\n",
    "selected_subset = list()\n",
    "\n",
    "ranks = [1, 5, 10, 25, 50, 75, 100]\n",
    "for r_i in ranks:\n",
    "    selected_subset.append( all_final_sets_all_N[r_i-1])\n",
    "\n",
    "for i, cross_all in zip(ranks, selected_subset):\n",
    "    all_data_top_N = list()\n",
    "    training_budgets = [4, 12, 36, 108]\n",
    "\n",
    "    for tuple_id_model in cross_all:\n",
    "        local_cell = api.ModelSpec(matrix= tuple_id_model[0],\n",
    "            # Operations at the vertices of the module, matches order of matrix.\n",
    "            ops= tuple_id_model[1])\n",
    "\n",
    "        local_eval_data = {budget_i:nasbench.query(local_cell, epochs=budget_i) for budget_i in training_budgets} \n",
    "        all_data_top_N.append( (tuple_id_model[0], tuple_id_model[1], local_eval_data) )\n",
    "\n",
    "\n",
    "    y_test_kappa_4 = [d[4]['test_accuracy'] for (_,_,d) in all_data_top_N]\n",
    "    y_test_kappa_12 = [d[12]['test_accuracy'] for (_,_,d) in all_data_top_N]\n",
    "    y_test_kappa_36 = [d[36]['test_accuracy'] for (_,_,d) in all_data_top_N]\n",
    "    y_test_kappa_108 = [d[108]['test_accuracy'] for (_,_,d) in all_data_top_N]\n",
    "    \n",
    "    all_testAcc_All_regimes_N_ranks.append( (y_test_kappa_4, y_test_kappa_12, \n",
    "                                             y_test_kappa_36, y_test_kappa_108)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,6))\n",
    "\n",
    "#for i, \n",
    "\n",
    "for rank_i, ys_test_rank_i in zip(ranks, all_testAcc_All_regimes_N_ranks):\n",
    "    \n",
    "    y_test_rank_i = ys_test_rank_i[0]\n",
    "    \n",
    "    if rank_i == 100:\n",
    "        plt.xlim(0.25, max(y_test_rank_i) + 0.05)\n",
    "        \n",
    "        sns.distplot(y_test_rank_i, hist = False, kde = True,\n",
    "                 kde_kws = {'linewidth': 2},\n",
    "                 label = \"reference (100%) \"+ '- N = ' + str(len(y_test_rank_i)), rug=False)\n",
    "    else:\n",
    "\n",
    "        sns.distplot(y_test_rank_i, hist = False, kde = True,\n",
    "                         kde_kws = {'linewidth': 2}, \n",
    "                         label = \"rank - \" + str(rank_i) +'%' + '    N = ' + str(len(y_test_rank_i)) , rug=False)\n",
    "\n",
    "plt.title(label='Evolution of Accuracies (PdFs) by Rank (Top-N% - Persistent 4-to-108) - CIFAR10 - 4 Epochs')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,6))\n",
    "#plt.xlim(0.4, max(y_test_kappa_108) + 0.01)\n",
    "#for i, \n",
    "for rank_i, ys_test_rank_i in zip(ranks, all_testAcc_All_regimes_N_ranks):\n",
    "    \n",
    "    y_test_rank_i = ys_test_rank_i[1]\n",
    "    \n",
    "    if rank_i == 100:\n",
    "        plt.xlim(0.65, max(y_test_rank_i) + 0.05)\n",
    "        \n",
    "        sns.distplot(y_test_rank_i, hist = False, kde = True,\n",
    "                 kde_kws = {'linewidth': 2},\n",
    "                 label = \"reference (100%) \"+ '- N = ' + str(len(y_test_rank_i)), rug=False)\n",
    "    else:\n",
    "\n",
    "        sns.distplot(y_test_rank_i, hist = False, kde = True,\n",
    "                         kde_kws = {'linewidth': 2}, \n",
    "                         label = \"rank: Top-\" + str(rank_i) +'%' + '    N = ' + str(len(y_test_rank_i)) , rug=False)\n",
    "plt.title(label='Evolution of Accuracies (PdFs) by Rank - CIFAR10 - 12 Epochs- (All Persistent 4-to-108) ')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,6))\n",
    "#plt.xlim(0.88, max(y_test_kappa_36_reference) + 0.01)\n",
    "\n",
    "for rank_i, ys_test_rank_i in zip(ranks, all_testAcc_All_regimes_N_ranks):\n",
    "    \n",
    "    y_test_rank_i = ys_test_rank_i[2]\n",
    "    \n",
    "    \n",
    "    if rank_i == 100:\n",
    "        #plt.ylim(0, 700)\n",
    "        plt.xlim(0.88, max(y_test_rank_i) )\n",
    "        \n",
    "        sns.distplot(y_test_rank_i, hist = False, kde = True,\n",
    "                 kde_kws = {'linewidth': 2},\n",
    "                 label = \"reference (100%) \"+ '- N = ' + str(len(y_test_rank_i)), rug=False)\n",
    "   \n",
    "    else:\n",
    "        \n",
    "        sns.distplot(y_test_rank_i, hist = False, kde = True,\n",
    "                         kde_kws = {'linewidth': 2}, \n",
    "                         label = \"rank - \" + str(rank_i) +'%' + '    N = ' + str(len(y_test_rank_i)) , rug=False)\n",
    "\n",
    "plt.title(label='Evolution of Accuracies (PdFs) by Rank (Top-N% - Persistent 4-to-108) - CIFAR10 - 36 Epochs')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,6))\n",
    "#plt.xlim(0.88, max(y_test_kappa_36_reference) + 0.01)\n",
    "\n",
    "for rank_i, ys_test_rank_i in zip(ranks, all_testAcc_All_regimes_N_ranks):\n",
    "    \n",
    "    y_test_rank_i = ys_test_rank_i[3]\n",
    "    \n",
    "    if rank_i == 100:\n",
    "        plt.xlim(0.91, max(y_test_rank_i) )\n",
    "        plt.ylim(0, 1200 )\n",
    "        \n",
    "        sns.distplot(y_test_rank_i, hist = False, kde = True,\n",
    "                 kde_kws = {'linewidth': 2},\n",
    "                 label = \"reference (100%) \"+ '- N = ' + str(len(y_test_rank_i)), rug=False)\n",
    "    if rank_i == 5:\n",
    "        sns.distplot(y_test_rank_i, hist = False, kde = True,\n",
    "                         kde_kws = {'linewidth': 0.8}, \n",
    "                         label = \"rank - \" + str(rank_i) +'%' + '    N = ' + str(len(y_test_rank_i)) , rug=True)\n",
    "    else:\n",
    "\n",
    "        sns.distplot(y_test_rank_i, hist = False, kde = True,\n",
    "                         kde_kws = {'linewidth': 2}, \n",
    "                         label = \"rank - \" + str(rank_i) +'%' + '    N = ' + str(len(y_test_rank_i)) , rug=False)\n",
    "\n",
    "plt.title(label='Evolution of Accuracies (PdFs) by Rank (Top-N%) - CIFAR10 - 108 Epochs')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_testAcc_All_regimes_N_ranks = list()\n",
    "\n",
    "selected_subset = list()\n",
    "\n",
    "ranks = [1, 5, 10, 25, 50, 75, 100]\n",
    "for r_i in ranks:\n",
    "    selected_subset.append( all_final_sets_all_N[r_i-1])\n",
    "\n",
    "for i, cross_all in zip(ranks, selected_subset):\n",
    "    all_data_top_N = list()\n",
    "    training_budgets = [4, 12, 36, 108]\n",
    "\n",
    "    for tuple_id_model in cross_all:\n",
    "        local_cell = api.ModelSpec(matrix= tuple_id_model[0],\n",
    "            # Operations at the vertices of the module, matches order of matrix.\n",
    "            ops= tuple_id_model[1])\n",
    "\n",
    "        local_eval_data = {budget_i:nasbench.query(local_cell, epochs=budget_i) for budget_i in training_budgets} \n",
    "        all_data_top_N.append( (tuple_id_model[0], tuple_id_model[1], local_eval_data) )\n",
    "\n",
    "\n",
    "    y_test_kappa_4 = [d[4]['training_time'] for (_,_,d) in all_data_top_N]\n",
    "    y_test_kappa_12 = [d[12]['training_time'] for (_,_,d) in all_data_top_N]\n",
    "    y_test_kappa_36 = [d[36]['training_time'] for (_,_,d) in all_data_top_N]\n",
    "    y_test_kappa_108 = [d[108]['training_time'] for (_,_,d) in all_data_top_N]\n",
    "    \n",
    "    all_testAcc_All_regimes_N_ranks.append( (y_test_kappa_4, y_test_kappa_12, \n",
    "                                             y_test_kappa_36, y_test_kappa_108)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,6))\n",
    "\n",
    "#for i, \n",
    "\n",
    "for rank_i, ys_test_rank_i in zip(ranks, all_testAcc_All_regimes_N_ranks):\n",
    "    \n",
    "    y_test_rank_i = ys_test_rank_i[3]\n",
    "    \n",
    "    if rank_i == 100:\n",
    "        plt.xlim(0.2, max(y_test_rank_i) + 0.05)\n",
    "        \n",
    "        sns.distplot(y_test_rank_i, hist = False, kde = True,\n",
    "                 kde_kws = {'linewidth': 2},\n",
    "                 label = \"reference (100%) \"+ '- N = ' + str(len(y_test_rank_i)), rug=False)\n",
    "    else:\n",
    "\n",
    "        sns.distplot(y_test_rank_i, hist = False, kde = True,\n",
    "                         kde_kws = {'linewidth': 2}, \n",
    "                         label = \"rank - \" + str(rank_i) +'%' + '    N = ' + str(len(y_test_rank_i)) , rug=False)\n",
    "\n",
    "plt.title(label='Evolution of Training Time (PdFs) by Rank (Top-N% - Persistent 4-to-108) - CIFAR10 - 108 Epochs')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Training Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_testAcc_All_regimes_N_ranks = list()\n",
    "\n",
    "selected_subset = list()\n",
    "\n",
    "ranks = [1, 5, 10, 25, 50, 75, 100]\n",
    "for r_i in ranks:\n",
    "    selected_subset.append( all_final_sets_all_N[r_i-1])\n",
    "\n",
    "for i, cross_all in zip(ranks, selected_subset):\n",
    "    all_data_top_N = list()\n",
    "    training_budgets = [4, 12, 36, 108]\n",
    "\n",
    "    for tuple_id_model in cross_all:\n",
    "        local_cell = api.ModelSpec(matrix= tuple_id_model[0],\n",
    "            # Operations at the vertices of the module, matches order of matrix.\n",
    "            ops= tuple_id_model[1])\n",
    "\n",
    "        local_eval_data = {budget_i:nasbench.query(local_cell, epochs=budget_i) for budget_i in training_budgets} \n",
    "        all_data_top_N.append( (tuple_id_model[0], tuple_id_model[1], local_eval_data) )\n",
    "\n",
    "\n",
    "    y_test_kappa_4 = [d[4]['trainable_parameters'] for (_,_,d) in all_data_top_N]\n",
    "    y_test_kappa_12 = [d[12]['trainable_parameters'] for (_,_,d) in all_data_top_N]\n",
    "    y_test_kappa_36 = [d[36]['trainable_parameters'] for (_,_,d) in all_data_top_N]\n",
    "    y_test_kappa_108 = [d[108]['trainable_parameters'] for (_,_,d) in all_data_top_N]\n",
    "    \n",
    "    all_testAcc_All_regimes_N_ranks.append( (y_test_kappa_4, y_test_kappa_12, \n",
    "                                             y_test_kappa_36, y_test_kappa_108)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,6))\n",
    "\n",
    "#for i, \n",
    "\n",
    "for rank_i, ys_test_rank_i in zip(ranks, all_testAcc_All_regimes_N_ranks):\n",
    "    \n",
    "    y_test_rank_i = ys_test_rank_i[3]\n",
    "    \n",
    "    if rank_i == 100:\n",
    "        plt.xlim(0.2, max(y_test_rank_i) + 0.05)\n",
    "        \n",
    "        sns.distplot(y_test_rank_i, hist = False, kde = True,\n",
    "                 kde_kws = {'linewidth': 2},\n",
    "                 label = \"reference (100%) \"+ '- N = ' + str(len(y_test_rank_i)), rug=False)\n",
    "    else:\n",
    "\n",
    "        sns.distplot(y_test_rank_i, hist = False, kde = True,\n",
    "                         kde_kws = {'linewidth': 2}, \n",
    "                         label = \"rank - \" + str(rank_i) +'%' + '    N = ' + str(len(y_test_rank_i)) , rug=False)\n",
    "\n",
    "plt.title(label='Evolution of SIZE (PdFs) by Rank (Top-N% - Persistent 4-to-108) - CIFAR10 - 108 Epochs')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('SIZE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Num Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_testAcc_All_regimes_N_ranks = list()\n",
    "\n",
    "selected_subset = list()\n",
    "\n",
    "ranks = [1, 5, 10, 25, 50, 75, 100]\n",
    "for r_i in ranks:\n",
    "    selected_subset.append( all_final_sets_all_N[r_i-1])\n",
    "\n",
    "for i, cross_all in zip(ranks, selected_subset):\n",
    "    all_data_top_N = list()\n",
    "    training_budgets = [4, 12, 36, 108]\n",
    "\n",
    "    for tuple_id_model in cross_all:\n",
    "        local_cell = api.ModelSpec(matrix= tuple_id_model[0],\n",
    "            # Operations at the vertices of the module, matches order of matrix.\n",
    "            ops= tuple_id_model[1])\n",
    "\n",
    "        local_eval_data = {budget_i:nasbench.query(local_cell, epochs=budget_i) for budget_i in training_budgets} \n",
    "        all_data_top_N.append( (tuple_id_model[0], tuple_id_model[1], local_eval_data) )\n",
    "\n",
    "\n",
    "    y_test_kappa_4 = [np.sum(d) for (d,_,_) in all_data_top_N]\n",
    "    all_testAcc_All_regimes_N_ranks.append(y_test_kappa_4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_top_N[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_testAcc_All_regimes_N_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,6))\n",
    "\n",
    "#for i, \n",
    "\n",
    "for rank_i, ys_test_rank_i in zip(ranks, all_testAcc_All_regimes_N_ranks):\n",
    "    \n",
    "    y_test_rank_i = ys_test_rank_i\n",
    "    \n",
    "    if rank_i == 100:\n",
    "        plt.xlim(0.2, max(y_test_rank_i) + 0.05)\n",
    "        \n",
    "        sns.distplot(y_test_rank_i, hist = False, kde = True,\n",
    "                 kde_kws = {'linewidth': 2},\n",
    "                 label = \"reference (100%) \"+ '- N = ' + str(len(y_test_rank_i)), rug=False)\n",
    "    else:\n",
    "\n",
    "        sns.distplot(y_test_rank_i, hist = False, kde = True,\n",
    "                         kde_kws = {'linewidth': 2}, \n",
    "                         label = \"rank - \" + str(rank_i) +'%' + '    N = ' + str(len(y_test_rank_i)) , rug=False)\n",
    "\n",
    "plt.title(label='Evolution of SIZE (PdFs) by Rank (Top-N% - Persistent 4-to-108) - CIFAR10 - 108 Epochs')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Num Edges')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_top_N[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_kappa_4 = [d[4]['test_accuracy'] for (_,_,d) in all_data_top_N]\n",
    "y_test_kappa_12 = [d[12]['test_accuracy'] for (_,_,d) in all_data_top_N]\n",
    "y_test_kappa_36 = [d[36]['test_accuracy'] for (_,_,d) in all_data_top_N]\n",
    "y_test_kappa_108 = [d[108]['test_accuracy'] for (_,_,d) in all_data_top_N]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(13,6))\n",
    "plt.xlim(0.4, max(y_test_kappa_108) + 0.01)\n",
    "sns.distplot(y_test_kappa_4, hist = False, kde = True,\n",
    "                 kde_kws = {'linewidth': 1}, \n",
    "                 label = \"Density of OA test 4e\", rug=False)\n",
    "sns.distplot(y_test_kappa_12, hist = False, kde = True,\n",
    "                 kde_kws = {'linewidth': 1},\n",
    "                 label = \"Density of OA test 12e\", rug=False)\n",
    "sns.distplot(y_test_kappa_36, hist = False, kde = True,\n",
    "                 kde_kws = {'linewidth': 1},\n",
    "                 label = \"Density of OA test 36e\", rug=False)\n",
    "sns.distplot(y_test_kappa_108, hist = False, kde = True,\n",
    "                 kde_kws = {'linewidth': 1},\n",
    "                 label = \"Density of train 108e\", rug=False)\n",
    "plt.title(label='s')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_kappa_4_reference = [d['test_accuracy'] for (_,_,d) in all_data_4_cf10] \n",
    "\n",
    "plt.figure(figsize=(13,6))\n",
    "#plt.xlim(0.4, max(y_test_kappa_108) + 0.01)\n",
    "sns.distplot(y_test_kappa_4, hist = False, kde = True,\n",
    "                 kde_kws = {'linewidth': 1}, \n",
    "                 label = \"Density of OA test 4e\", rug=False)\n",
    "sns.distplot(y_test_kappa_4_reference, hist = False, kde = True,\n",
    "                 kde_kws = {'linewidth': 1},\n",
    "                 label = \"Density of OA test 4 - reference\", rug=False)\n",
    "plt.title(label='s')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_kappa_12_reference = [d['test_accuracy'] for (_,_,d) in all_data_12_cf10] \n",
    "\n",
    "plt.figure(figsize=(13,6))\n",
    "#plt.xlim(0.4, max(y_test_kappa_108) + 0.01)\n",
    "sns.distplot(y_test_kappa_12, hist = False, kde = True,\n",
    "                 kde_kws = {'linewidth': 1}, \n",
    "                 label = \"Density of OA test 12\", rug=False)\n",
    "sns.distplot(y_test_kappa_12_reference, hist = False, kde = True,\n",
    "                 kde_kws = {'linewidth': 1},\n",
    "                 label = \"Density of OA test 12 - reference\", rug=False)\n",
    "plt.title(label='s')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_kappa_36_reference = [d['test_accuracy'] for (_,_,d) in all_data_36_cf10] \n",
    "y_test_kappa_108_reference = [d['test_accuracy'] for (_,_,d) in all_data_108_cf10] \n",
    "\n",
    "plt.figure(figsize=(13,6))\n",
    "plt.xlim(0.4, max(y_test_kappa_108_reference) + 0.01)\n",
    "sns.distplot(y_test_kappa_36, hist = False, kde = True,\n",
    "                 kde_kws = {'linewidth': 1}, \n",
    "                 label = \"Density of OA test 36\", rug=False)\n",
    "sns.distplot(y_test_kappa_36_reference, hist = False, kde = True,\n",
    "                 kde_kws = {'linewidth': 1},\n",
    "                 label = \"Density of OA test 36 - reference\", rug=False)\n",
    "plt.title(label='s')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_kappa_108_reference = [d['test_accuracy'] for (_,_,d) in all_data_108_cf10] \n",
    "\n",
    "plt.figure(figsize=(13,6))\n",
    "plt.xlim(0.4, max(y_test_kappa_108_reference) + 0.01)\n",
    "sns.distplot(y_test_kappa_108, hist = False, kde = True,\n",
    "                 kde_kws = {'linewidth': 1}, \n",
    "                 label = \"Density of OA test 108e\", rug=False)\n",
    "sns.distplot(y_test_kappa_108_reference, hist = False, kde = True,\n",
    "                 kde_kws = {'linewidth': 1},\n",
    "                 label = \"Density of OA test 108 - reference\", rug=False)\n",
    "plt.title(label='s')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END - Density of States of TOP-N Performers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative TOP-N%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative = True\n",
    "size_inter_cifar10_top = []\n",
    "total_size = N_samples\n",
    "\n",
    "for N in range(1, 100 + 1):\n",
    "    #print(N)\n",
    "    top_n_r_04 = top_n_local(all_data_4_cf10, N=N, key='test_accuracy')\n",
    "    top_n_r_12 = top_n_local(all_data_12_cf10, N=N, key='test_accuracy')\n",
    "    top_n_r_36 = top_n_local(all_data_36_cf10, N=N, key='test_accuracy')\n",
    "    top_n_r_108 = top_n_local(all_data_108_cf10, N=N, key='test_accuracy')\n",
    "\n",
    "    top_n_r_4_models = [(m4, o4) for (m4, o4, _) in top_n_r_04]\n",
    "    #top_n_r_12_models = [(m12, o12) for (m12, o12, _) in top_n_r_12]\n",
    "    #top_n_r_36_models = [(m36, o36) for (m36, o36, _) in top_n_r_36]\n",
    "    #top_n_r_108_models = [(m108, o108) for (m108, o108, _) in top_n_r_108]\n",
    "\n",
    "    cross_4_12 = []\n",
    "    cross_4_12_36 = []\n",
    "    cross_all = []\n",
    "    \n",
    "    model_min12 = top_n_r_12[0]\n",
    "    model_max12 = top_n_r_12[len(top_n_r_12)-1]\n",
    "    #print(len(model_min12), len(model_max12))\n",
    "    min_ri_test_acc12 = min(model_min12[2]['test_accuracy'], model_max12[2]['test_accuracy'])\n",
    "    max_ri_test_acc12 = max(model_min12[2]['test_accuracy'], model_max12[2]['test_accuracy'])\n",
    "\n",
    "    for duo_i in top_n_r_04:\n",
    "        # in R = 12 \n",
    "        #for duo_j in top_25_r_12:\n",
    "        #    if np.all(duo_i[0] == duo_j[0]) and np.all(duo_i[1] == duo_j[1]) :\n",
    "        #        cross_4_12.append(duo_i)\n",
    "        cell = api.ModelSpec(\n",
    "          matrix= duo_i[0],\n",
    "          # Operations at the vertices of the module, matches order of matrix.\n",
    "          ops= duo_i[1])\n",
    "        data = nasbench.query(cell, epochs=12)\n",
    "        \n",
    "        if data['test_accuracy'] >= min_ri_test_acc12 and data['test_accuracy'] <= max_ri_test_acc12:\n",
    "            cross_4_12.append(duo_i)\n",
    "        \n",
    "    model_min36 = top_n_r_36[0]\n",
    "    model_max36 = top_n_r_36[len(top_n_r_36)-1]\n",
    "\n",
    "    min_ri_test_acc36 = min(model_min36[2]['test_accuracy'], model_max36[2]['test_accuracy'])\n",
    "    max_ri_test_acc36 = max(model_min36[2]['test_accuracy'], model_max36[2]['test_accuracy'])\n",
    "        \n",
    "    for duo_i in cross_4_12:\n",
    "        # in R = 12 \n",
    "        #for duo_j in top_25_r_36_models:\n",
    "        #    if np.all(duo_i[0] == duo_j[0]) and np.all(duo_i[1] == duo_j[1]) :\n",
    "        #        cross_4_12_36.append(duo_i)\n",
    "        cell = api.ModelSpec(\n",
    "          matrix= duo_i[0],\n",
    "          # Operations at the vertices of the module, matches order of matrix.\n",
    "          ops= duo_i[1])\n",
    "        data = nasbench.query(cell, epochs=36)\n",
    "        \n",
    "        if data['test_accuracy'] >= min_ri_test_acc36 and data['test_accuracy'] <= max_ri_test_acc36:\n",
    "            cross_4_12_36.append(duo_i)\n",
    "            \n",
    "    model_min108 = top_n_r_108[0]\n",
    "    model_max108 = top_n_r_108[len(top_n_r_108)-1]\n",
    "\n",
    "    min_ri_test_acc108 = min(model_min108[2]['test_accuracy'], model_max108[2]['test_accuracy'])\n",
    "    max_ri_test_acc108 = max(model_min108[2]['test_accuracy'], model_max108[2]['test_accuracy'])\n",
    "    \n",
    "    for duo_i in cross_4_12_36:\n",
    "        # in R = 12 \n",
    "        #for duo_j in top_25_r_108:\n",
    "        #    if np.all(duo_i[0] == duo_j[0]) and np.all(duo_i[1] == duo_j[1]) :\n",
    "        #        cross_all.append(duo_i)\n",
    "        \n",
    "        cell = api.ModelSpec(\n",
    "          matrix= duo_i[0],\n",
    "          # Operations at the vertices of the module, matches order of matrix.\n",
    "          ops= duo_i[1])\n",
    "        data = nasbench.query(cell, epochs=108)\n",
    "        \n",
    "        if data['test_accuracy'] >= min_ri_test_acc108 and data['test_accuracy'] <= max_ri_test_acc108:\n",
    "            cross_all.append(duo_i)\n",
    "            \n",
    "    if relative:\n",
    "        len_top_4 = len(top_n_r_04)       \n",
    "    else:\n",
    "        len_top_4 = total_size\n",
    "\n",
    "    l0, l1, l2, l3 = len(top_n_r_04) / len_top_4, len(cross_4_12)/len_top_4, len(cross_4_12_36)/len_top_4, len(cross_all)/len_top_4\n",
    "    size_inter_cifar10_top.append((l0 * 100, l1 * 100, l2 * 100, l3 * 100))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_top_size = 25\n",
    "ref_top_25_c10 = [s[0] for s in size_inter_cifar10_top][:N_top_size]\n",
    "np.min(ref_top_25_c10), np.max(ref_top_25_c10), np.sum(ref_top_25_c10)/ (100 * N_top_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_25_c10_list = [s[3] for s in size_inter_cifar10_top][:N_top_size]\n",
    "\n",
    "top_25_c10 = top_25_c10_list[len(top_25_c10_list)-1]\n",
    "auc_top_25_c10 = np.sum(top_25_c10_list)/ (100 * N_top_size)\n",
    "\n",
    "top_25_c10, auc_top_25_c10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Failure across time: models remaining Bottom-N% after being Bottom-N% at 4 epochs \\n CIFAR10'\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.ylim(0, 102) #len(mean_perf_half))\n",
    "plt.xlim(0, 100)\n",
    "#plt.set_xticks(5)\n",
    "plt.plot(range(1, 101), [s[0] for s in size_inter_cifar10_top], label = \"Across: [4] epochs (Reference)\",)\n",
    "plt.plot(range(1, 101), [s[1] for s in size_inter_cifar10_top], label = \"Across: [4, 12] epochs\",)\n",
    "plt.plot(range(1, 101), [s[2] for s in size_inter_cifar10_top], label = \"Across: [4, 12, 36] epochs)\",)\n",
    "plt.plot(range(1, 101), [s[3] for s in size_inter_cifar10_top], label = \"Across: [4, 12, 36, 108] epochs\",)\n",
    "plt.title(label=title)\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Bottom-N (in %)')\n",
    "plt.ylabel('Size of intersection (%)')\n",
    "#plt.axvline(x=10, color='red')\n",
    "#plt.axvline(x=25, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bottom-N%: \n",
    "### Absolute Bottom-N%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative = False\n",
    "size_inter_cifar10_bottom = []\n",
    "total_size = N_samples\n",
    "\n",
    "for N in range(1, 100 + 1):\n",
    "    #print(N)\n",
    "    top_n_r_04 = bottom_n_local(all_data_4_cf10, N=N, key='test_accuracy')\n",
    "    top_n_r_12 = bottom_n_local(all_data_12_cf10, N=N, key='test_accuracy')\n",
    "    top_n_r_36 = bottom_n_local(all_data_36_cf10, N=N, key='test_accuracy')\n",
    "    top_n_r_108 = bottom_n_local(all_data_108_cf10, N=N, key='test_accuracy')\n",
    "\n",
    "    top_n_r_4_models = [(m4, o4) for (m4, o4, _) in top_n_r_04]\n",
    "    #top_n_r_12_models = [(m12, o12) for (m12, o12, _) in top_n_r_12]\n",
    "    #top_n_r_36_models = [(m36, o36) for (m36, o36, _) in top_n_r_36]\n",
    "    #top_n_r_108_models = [(m108, o108) for (m108, o108, _) in top_n_r_108]\n",
    "\n",
    "    cross_4_12 = []\n",
    "    cross_4_12_36 = []\n",
    "    cross_all = []\n",
    "    \n",
    "    model_min12 = top_n_r_12[0]\n",
    "    model_max12 = top_n_r_12[len(top_n_r_12)-1]\n",
    "    #print(len(model_min12), len(model_max12))\n",
    "    min_ri_test_acc12 = min(model_min12[2]['test_accuracy'], model_max12[2]['test_accuracy'])\n",
    "    max_ri_test_acc12 = max(model_min12[2]['test_accuracy'], model_max12[2]['test_accuracy'])\n",
    "\n",
    "    for duo_i in top_n_r_04:\n",
    "        # in R = 12 \n",
    "        #for duo_j in top_25_r_12:\n",
    "        #    if np.all(duo_i[0] == duo_j[0]) and np.all(duo_i[1] == duo_j[1]) :\n",
    "        #        cross_4_12.append(duo_i)\n",
    "        cell = api.ModelSpec(\n",
    "          matrix= duo_i[0],\n",
    "          # Operations at the vertices of the module, matches order of matrix.\n",
    "          ops= duo_i[1])\n",
    "        data = nasbench.query(cell, epochs=12)\n",
    "        \n",
    "        if data['test_accuracy'] >= min_ri_test_acc12 and data['test_accuracy'] <= max_ri_test_acc12:\n",
    "            cross_4_12.append(duo_i)\n",
    "        \n",
    "    model_min36 = top_n_r_36[0]\n",
    "    model_max36 = top_n_r_36[len(top_n_r_36)-1]\n",
    "\n",
    "    min_ri_test_acc36 = min(model_min36[2]['test_accuracy'], model_max36[2]['test_accuracy'])\n",
    "    max_ri_test_acc36 = max(model_min36[2]['test_accuracy'], model_max36[2]['test_accuracy'])\n",
    "        \n",
    "    for duo_i in cross_4_12:\n",
    "        # in R = 12 \n",
    "        #for duo_j in top_25_r_36_models:\n",
    "        #    if np.all(duo_i[0] == duo_j[0]) and np.all(duo_i[1] == duo_j[1]) :\n",
    "        #        cross_4_12_36.append(duo_i)\n",
    "        cell = api.ModelSpec(\n",
    "          matrix= duo_i[0],\n",
    "          # Operations at the vertices of the module, matches order of matrix.\n",
    "          ops= duo_i[1])\n",
    "        data = nasbench.query(cell, epochs=36)\n",
    "        \n",
    "        if data['test_accuracy'] >= min_ri_test_acc36 and data['test_accuracy'] <= max_ri_test_acc36:\n",
    "            cross_4_12_36.append(duo_i)\n",
    "            \n",
    "    model_min108 = top_n_r_108[0]\n",
    "    model_max108 = top_n_r_108[len(top_n_r_108)-1]\n",
    "\n",
    "    min_ri_test_acc108 = min(model_min108[2]['test_accuracy'], model_max108[2]['test_accuracy'])\n",
    "    max_ri_test_acc108 = max(model_min108[2]['test_accuracy'], model_max108[2]['test_accuracy'])\n",
    "    \n",
    "    for duo_i in cross_4_12_36:\n",
    "        # in R = 12 \n",
    "        #for duo_j in top_25_r_108:\n",
    "        #    if np.all(duo_i[0] == duo_j[0]) and np.all(duo_i[1] == duo_j[1]) :\n",
    "        #        cross_all.append(duo_i)\n",
    "        \n",
    "        cell = api.ModelSpec(\n",
    "          matrix= duo_i[0],\n",
    "          # Operations at the vertices of the module, matches order of matrix.\n",
    "          ops= duo_i[1])\n",
    "        data = nasbench.query(cell, epochs=108)\n",
    "        \n",
    "        if data['test_accuracy'] >= min_ri_test_acc108 and data['test_accuracy'] <= max_ri_test_acc108:\n",
    "            cross_all.append(duo_i)\n",
    "            \n",
    "    if relative:\n",
    "        len_top_4 = len(top_n_r_04)\n",
    "        assert len_top_4 == N\n",
    "    else:\n",
    "        len_top_4 = total_size\n",
    "\n",
    "    l0, l1, l2, l3 = len(top_n_r_04) / len_top_4, len(cross_4_12)/len_top_4, len(cross_4_12_36)/len_top_4, len(cross_all)/len_top_4\n",
    "    size_inter_cifar10_bottom.append((l0 * 100, l1 * 100, l2 * 100, l3 * 100))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Failure across time: models remaining Bottom-N% after being Bottom-N% at 4 epochs \\n CIFAR10'\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.ylim(0, 102) #len(mean_perf_half))\n",
    "plt.xlim(0, 100)\n",
    "#plt.set_xticks(5)\n",
    "plt.plot(range(1, 101), [s[0] for s in size_inter_cifar10_bottom], label = \"Across: [4] epochs (Reference)\",)\n",
    "plt.plot(range(1, 101), [s[1] for s in size_inter_cifar10_bottom], label = \"Across: [4, 12] epochs\",)\n",
    "plt.plot(range(1, 101), [s[2] for s in size_inter_cifar10_bottom], label = \"Across: [4, 12, 36] epochs)\",)\n",
    "plt.plot(range(1, 101), [s[3] for s in size_inter_cifar10_bottom], label = \"Across: [4, 12, 36, 108] epochs\",)\n",
    "plt.title(label=title)\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Bottom-N (in %)')\n",
    "plt.ylabel('Size of intersection (%)')\n",
    "#plt.axvline(x=10, color='red')\n",
    "#plt.axvline(x=25, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative Bottom-N%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative = True\n",
    "size_inter_cifar10_bottom_rel = []\n",
    "total_size = N_samples\n",
    "\n",
    "for N in range(1, 100 + 1):\n",
    "    #print(N)\n",
    "    top_n_r_04 = bottom_n_local(all_data_4_cf10, N=N, key='test_accuracy')\n",
    "    top_n_r_12 = bottom_n_local(all_data_12_cf10, N=N, key='test_accuracy')\n",
    "    top_n_r_36 = bottom_n_local(all_data_36_cf10, N=N, key='test_accuracy')\n",
    "    top_n_r_108 = bottom_n_local(all_data_108_cf10, N=N, key='test_accuracy')\n",
    "\n",
    "    top_n_r_4_models = [(m4, o4) for (m4, o4, _) in top_n_r_04]\n",
    "    #top_n_r_12_models = [(m12, o12) for (m12, o12, _) in top_n_r_12]\n",
    "    #top_n_r_36_models = [(m36, o36) for (m36, o36, _) in top_n_r_36]\n",
    "    #top_n_r_108_models = [(m108, o108) for (m108, o108, _) in top_n_r_108]\n",
    "\n",
    "    cross_4_12 = []\n",
    "    cross_4_12_36 = []\n",
    "    cross_all = []\n",
    "    \n",
    "    model_min12 = top_n_r_12[0]\n",
    "    model_max12 = top_n_r_12[len(top_n_r_12)-1]\n",
    "    #print(len(model_min12), len(model_max12))\n",
    "    min_ri_test_acc12 = min(model_min12[2]['test_accuracy'], model_max12[2]['test_accuracy'])\n",
    "    max_ri_test_acc12 = max(model_min12[2]['test_accuracy'], model_max12[2]['test_accuracy'])\n",
    "\n",
    "    for duo_i in top_n_r_04:\n",
    "        # in R = 12 \n",
    "        #for duo_j in top_25_r_12:\n",
    "        #    if np.all(duo_i[0] == duo_j[0]) and np.all(duo_i[1] == duo_j[1]) :\n",
    "        #        cross_4_12.append(duo_i)\n",
    "        cell = api.ModelSpec(\n",
    "          matrix= duo_i[0],\n",
    "          # Operations at the vertices of the module, matches order of matrix.\n",
    "          ops= duo_i[1])\n",
    "        data = nasbench.query(cell, epochs=12)\n",
    "        \n",
    "        if data['test_accuracy'] >= min_ri_test_acc12 and data['test_accuracy'] <= max_ri_test_acc12:\n",
    "            cross_4_12.append(duo_i)\n",
    "        \n",
    "    model_min36 = top_n_r_36[0]\n",
    "    model_max36 = top_n_r_36[len(top_n_r_36)-1]\n",
    "\n",
    "    min_ri_test_acc36 = min(model_min36[2]['test_accuracy'], model_max36[2]['test_accuracy'])\n",
    "    max_ri_test_acc36 = max(model_min36[2]['test_accuracy'], model_max36[2]['test_accuracy'])\n",
    "        \n",
    "    for duo_i in cross_4_12:\n",
    "        # in R = 12 \n",
    "        #for duo_j in top_25_r_36_models:\n",
    "        #    if np.all(duo_i[0] == duo_j[0]) and np.all(duo_i[1] == duo_j[1]) :\n",
    "        #        cross_4_12_36.append(duo_i)\n",
    "        cell = api.ModelSpec(\n",
    "          matrix= duo_i[0],\n",
    "          # Operations at the vertices of the module, matches order of matrix.\n",
    "          ops= duo_i[1])\n",
    "        data = nasbench.query(cell, epochs=36)\n",
    "        \n",
    "        if data['test_accuracy'] >= min_ri_test_acc36 and data['test_accuracy'] <= max_ri_test_acc36:\n",
    "            cross_4_12_36.append(duo_i)\n",
    "            \n",
    "    model_min108 = top_n_r_108[0]\n",
    "    model_max108 = top_n_r_108[len(top_n_r_108)-1]\n",
    "\n",
    "    min_ri_test_acc108 = min(model_min108[2]['test_accuracy'], model_max108[2]['test_accuracy'])\n",
    "    max_ri_test_acc108 = max(model_min108[2]['test_accuracy'], model_max108[2]['test_accuracy'])\n",
    "    \n",
    "    for duo_i in cross_4_12_36:\n",
    "        # in R = 12 \n",
    "        #for duo_j in top_25_r_108:\n",
    "        #    if np.all(duo_i[0] == duo_j[0]) and np.all(duo_i[1] == duo_j[1]) :\n",
    "        #        cross_all.append(duo_i)\n",
    "        \n",
    "        cell = api.ModelSpec(\n",
    "          matrix= duo_i[0],\n",
    "          # Operations at the vertices of the module, matches order of matrix.\n",
    "          ops= duo_i[1])\n",
    "        data = nasbench.query(cell, epochs=108)\n",
    "        \n",
    "        if data['test_accuracy'] >= min_ri_test_acc108 and data['test_accuracy'] <= max_ri_test_acc108:\n",
    "            cross_all.append(duo_i)\n",
    "            \n",
    "    if relative:\n",
    "        len_top_4 = len(top_n_r_04)\n",
    "        #print(N, len(top_n_r_04))\n",
    "        assert len_top_4 == N  * 10\n",
    "    else:\n",
    "        len_top_4 = total_size\n",
    "\n",
    "    l0, l1, l2, l3 = len(top_n_r_04) / len_top_4, len(cross_4_12)/len_top_4, len(cross_4_12_36)/len_top_4, len(cross_all)/len_top_4\n",
    "    size_inter_cifar10_bottom_rel.append((l0 * 100, l1 * 100, l2 * 100, l3 * 100))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Failure across time: models remaining Bottom-N% after being Bottom-N% at 4 epochs \\n CIFAR10'\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.ylim(0, 102) #len(mean_perf_half))\n",
    "plt.xlim(0, 100)\n",
    "#plt.set_xticks(5)\n",
    "plt.plot(range(1, 101), [s[0] for s in size_inter_cifar10_bottom_rel], label = \"Across: [4] epochs (Reference)\",)\n",
    "plt.plot(range(1, 101), [s[1] for s in size_inter_cifar10_bottom_rel], label = \"Across: [4, 12] epochs\",)\n",
    "plt.plot(range(1, 101), [s[2] for s in size_inter_cifar10_bottom_rel], label = \"Across: [4, 12, 36] epochs)\",)\n",
    "plt.plot(range(1, 101), [s[3] for s in size_inter_cifar10_bottom_rel], label = \"Across: [4, 12, 36, 108] epochs\",)\n",
    "plt.title(label=title)\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Bottom-N (in %)')\n",
    "plt.ylabel('Size of intersection (%)')\n",
    "#plt.axvline(x=10, color='red')\n",
    "#plt.axvline(x=25, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_bottom_size = 25\n",
    "ref_bottom_25_c10 = [s[0] for s in size_inter_cifar10_bottom_rel][:N_top_size]\n",
    "np.min(ref_bottom_25_c10), np.max(ref_bottom_25_c10), np.sum(ref_bottom_25_c10)/ (100 * N_bottom_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_25_c10_list = [s[3] for s in size_inter_cifar10_bottom_rel][:N_top_size]\n",
    "\n",
    "bottom_25_c10 = bottom_25_c10_list[len(bottom_25_c10_list)-1]\n",
    "auc_bottom_25_c10 = np.sum(bottom_25_c10_list)/ (100 * N_bottom_size)\n",
    "\n",
    "bottom_25_c10, auc_bottom_25_c10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness across datasets (LCZ42 -> Cifar10):\n",
    "\n",
    "### Absolute Top-N%:  crossing single regimes (comparing 4 with 4, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "key = 'test_accuracy'\n",
    "size_inter_all = dict()\n",
    "\n",
    "all_cifar_regimes = [all_data_4_cf10, all_data_12_cf10, all_data_36_cf10, all_data_108_cf10]\n",
    "\n",
    "for cf_10_ri, ri in zip(all_cifar_regimes, [4, 12, 36, 108]):\n",
    "    \n",
    "    sorted_by_key = sorted(cf_10_ri, key= lambda triplet: triplet[2][key]) \n",
    "    size_inter_all[ri] = list()\n",
    "    \n",
    "    for N in range(1, 101):        \n",
    "\n",
    "        key = 'test_accuracy'\n",
    "        top_n_idx = len(sorted_by_key) * N/100\n",
    "        top_n_idx = round(top_n_idx)\n",
    "\n",
    "        top_n_r_cf10 = sorted_by_key[-top_n_idx:]\n",
    "\n",
    "        top_n_ri_lcz42 = top_n(mean_perf_half, N=N, regime=ri, key='kappaCohen_test')\n",
    "\n",
    "        model_min = top_n_r_cf10[0]\n",
    "        model_max = top_n_r_cf10[len(top_n_r_cf10)-1]\n",
    "\n",
    "        min_ri_test_acc = min(model_min[2]['test_accuracy'], model_max[2]['test_accuracy'])\n",
    "        max_ri_test_acc = max(model_min[2]['test_accuracy'], model_max[2]['test_accuracy'])\n",
    "\n",
    "\n",
    "        cross_cf10_lcz42 = []\n",
    "        for m, o, cell in top_n_ri_lcz42:\n",
    "            # Query an Inception-like cell from the dataset.\n",
    "            cell = api.ModelSpec(\n",
    "              matrix= m.astype(int),\n",
    "              # Operations at the vertices of the module, matches order of matrix.\n",
    "              ops= o) #[INPUT, CONV1X1, CONV3X3, CONV3X3, CONV3X3, MAXPOOL3X3, OUTPUT])\n",
    "\n",
    "            data = nasbench.query(cell, epochs=ri)\n",
    "            if data['test_accuracy'] >= min_ri_test_acc and data['test_accuracy'] <= max_ri_test_acc:\n",
    "                cross_cf10_lcz42.append((m, o, data))\n",
    "        size_inter_all[ri].append(len(cross_cf10_lcz42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Robustness across datasets: models remaining Top-N% for same regimes'\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.ylim(0, 100) #len(mean_perf_half))\n",
    "plt.xlim(0, 100)\n",
    "#plt.set_xticks(5)\n",
    "plt.plot(range(1, 101), size_inter_all[4], label = \"Across: [4] epochs (Reference)\",)\n",
    "plt.plot(range(1, 101), size_inter_all[12], label = \"Across: [12] epochs (Reference)\",)\n",
    "plt.plot(range(1, 101), size_inter_all[36], label = \"Across: [36] epochs (Reference)\",)\n",
    "plt.plot(range(1, 101), size_inter_all[108], label = \"Across: [108] epochs (Reference)\",)\n",
    "plt.title(label=title)\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Top-N (in %)')\n",
    "plt.ylabel('Size of intersection (Number of models)')\n",
    "#plt.axvline(x=10, color='red')\n",
    "#plt.axvline(x=25, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Relative Top-N%:  crossing single regimes (comparing 4 with 4, etc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "key = 'test_accuracy'\n",
    "size_inter_all_rel = dict()\n",
    "\n",
    "all_cifar_regimes = [all_data_4_cf10, all_data_12_cf10, all_data_36_cf10, all_data_108_cf10]\n",
    "\n",
    "for cf_10_ri, ri in zip(all_cifar_regimes, [4, 12, 36, 108]):\n",
    "    \n",
    "    sorted_by_key = sorted(cf_10_ri, key= lambda triplet: triplet[2][key]) \n",
    "    size_inter_all_rel[ri] = list()\n",
    "    \n",
    "    for N in range(1, 101):        \n",
    "\n",
    "        key = 'test_accuracy'\n",
    "        top_n_idx = len(sorted_by_key) * N/100\n",
    "        top_n_idx = round(top_n_idx)\n",
    "\n",
    "        top_n_r_cf10 = sorted_by_key[-top_n_idx:]\n",
    "\n",
    "        top_n_ri_lcz42 = top_n(mean_perf_half, N=N, regime=ri, key='kappaCohen_test')\n",
    "\n",
    "        model_min = top_n_r_cf10[0]\n",
    "        model_max = top_n_r_cf10[len(top_n_r_cf10)-1]\n",
    "\n",
    "        min_ri_test_acc = min(model_min[2]['test_accuracy'], model_max[2]['test_accuracy'])\n",
    "        max_ri_test_acc = max(model_min[2]['test_accuracy'], model_max[2]['test_accuracy'])\n",
    "\n",
    "\n",
    "        cross_cf10_lcz42 = []\n",
    "        for m, o, cell in top_n_ri_lcz42:\n",
    "            # Query an Inception-like cell from the dataset.\n",
    "            cell = api.ModelSpec(\n",
    "              matrix= m.astype(int),\n",
    "              # Operations at the vertices of the module, matches order of matrix.\n",
    "              ops= o) #[INPUT, CONV1X1, CONV3X3, CONV3X3, CONV3X3, MAXPOOL3X3, OUTPUT])\n",
    "\n",
    "            data = nasbench.query(cell, epochs=ri)\n",
    "            if data['test_accuracy'] >= min_ri_test_acc and data['test_accuracy'] <= max_ri_test_acc:\n",
    "                cross_cf10_lcz42.append((m, o, data))\n",
    "        size_inter_all_rel[ri].append(100 * len(cross_cf10_lcz42) / len(top_n_ri_lcz42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Robustness across datasets: models remaining Top-N% for same regimes'\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.ylim(0, 100) #len(mean_perf_half))\n",
    "plt.xlim(0, 100)\n",
    "#plt.set_xticks(5)\n",
    "plt.plot(range(1, 101), size_inter_all_rel[4], label = \"Accross: [4] epochs (Reference)\",)\n",
    "plt.plot(range(1, 101), size_inter_all_rel[12], label = \"Accross: [12] epochs (Reference)\",)\n",
    "plt.plot(range(1, 101), size_inter_all_rel[36], label = \"Accross: [36] epochs (Reference)\",)\n",
    "plt.plot(range(1, 101), size_inter_all_rel[108], label = \"Accross: [108] epochs (Reference)\",)\n",
    "plt.title(label=title)\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Top-N (in %)')\n",
    "plt.ylabel('Size of intersection (%)')\n",
    "#plt.axvline(x=10, color='red')\n",
    "#plt.axvline(x=25, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Robustness across datasets: models remaining Top-N% for same regimes'\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.ylim(0, 60) #len(mean_perf_half))\n",
    "plt.xlim(0, 35)\n",
    "#plt.set_xticks(5)\n",
    "plt.plot(range(1, 101), size_inter_all_rel[4], label = \"Across: [4] epochs (Reference)\",)\n",
    "plt.plot(range(1, 101), size_inter_all_rel[12], label = \"Across: [12] epochs (Reference)\",)\n",
    "plt.plot(range(1, 101), size_inter_all_rel[36], label = \"Across: [36] epochs (Reference)\",)\n",
    "plt.plot(range(1, 101), size_inter_all_rel[108], label = \"Across: [108] epochs (Reference)\",)\n",
    "plt.title(label=title)\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Top-N (in %)')\n",
    "plt.ylabel('Size of intersection (%)')\n",
    "#plt.axvline(x=10, color='red')\n",
    "#plt.axvline(x=25, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Absolute Bottom-N%:  crossing single regimes (comparing 4 with 4, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_inter_all = dict()\n",
    "key = 'test_accuracy'\n",
    "all_cifar_regimes = [all_data_4_cf10, all_data_12_cf10, all_data_36_cf10, all_data_108_cf10]\n",
    "\n",
    "for cf_10_ri, ri in zip(all_cifar_regimes, [4, 12, 36, 108]):\n",
    "    \n",
    "    sorted_by_key = sorted(cf_10_ri, key= lambda triplet: triplet[2][key]) \n",
    "    size_inter_all[ri] = list()\n",
    "    \n",
    "    for N in range(1, 101):        \n",
    "\n",
    "        key = 'test_accuracy'\n",
    "        top_n_idx = len(sorted_by_key) * N/100\n",
    "        top_n_idx = round(top_n_idx)\n",
    "        #print(\"idxs: \" ,top_n_idx)\n",
    "        top_n_r_cf10 = sorted_by_key[:top_n_idx]\n",
    "\n",
    "        top_n_ri_lcz42 = bottom_n(mean_perf_half, N=N, regime=ri, key='kappaCohen_test')\n",
    "\n",
    "        model_min = top_n_r_cf10[0]\n",
    "        model_max = top_n_r_cf10[len(top_n_r_cf10)-1]\n",
    "\n",
    "        min_ri_test_acc = min(model_min[2]['test_accuracy'], model_max[2]['test_accuracy'])\n",
    "        max_ri_test_acc = max(model_min[2]['test_accuracy'], model_max[2]['test_accuracy'])\n",
    "\n",
    "\n",
    "        cross_cf10_lcz42 = []\n",
    "        for m, o, cell in top_n_ri_lcz42:\n",
    "            # Query an Inception-like cell from the dataset.\n",
    "            cell = api.ModelSpec(\n",
    "              matrix= m.astype(int),\n",
    "              # Operations at the vertices of the module, matches order of matrix.\n",
    "              ops= o) #[INPUT, CONV1X1, CONV3X3, CONV3X3, CONV3X3, MAXPOOL3X3, OUTPUT])\n",
    "\n",
    "            data = nasbench.query(cell, epochs=ri)\n",
    "            if data['test_accuracy'] >= min_ri_test_acc and data['test_accuracy'] <= max_ri_test_acc:\n",
    "                cross_cf10_lcz42.append((m, o, data))\n",
    "        size_inter_all[ri].append(len(cross_cf10_lcz42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Failure across datasets: models remaining Top-N% for same regimes'\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.ylim(0, 100) #len(mean_perf_half))\n",
    "plt.xlim(0, 100)\n",
    "#plt.set_xticks(5)\n",
    "plt.plot(range(1, 101), size_inter_all[4], label = \"Across: [4] epochs (Reference)\",)\n",
    "plt.plot(range(1, 101), size_inter_all[12], label = \"Across: [12] epochs (Reference)\",)\n",
    "plt.plot(range(1, 101), size_inter_all[36], label = \"Across: [36] epochs (Reference)\",)\n",
    "plt.plot(range(1, 101), size_inter_all[108], label = \"Across: [108] epochs (Reference)\",)\n",
    "plt.title(label=title)\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Bottom-N (in %)')\n",
    "plt.ylabel('Size of intersection (Number of models)')\n",
    "#plt.axvline(x=10, color='red')\n",
    "#plt.axvline(x=25, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Failure across datasets: models remaining Top-N% for same regimes'\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.ylim(0, 30) #len(mean_perf_half))\n",
    "plt.xlim(0, 40)\n",
    "#plt.set_xticks(5)\n",
    "plt.plot(range(1, 101), size_inter_all[4], label = \"Across: [4] epochs (Reference)\",)\n",
    "plt.plot(range(1, 101), size_inter_all[12], label = \"Across: [12] epochs (Reference)\",)\n",
    "plt.plot(range(1, 101), size_inter_all[36], label = \"Across: [36] epochs (Reference)\",)\n",
    "plt.plot(range(1, 101), size_inter_all[108], label = \"Across: [108] epochs (Reference)\",)\n",
    "plt.title(label=title)\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Bottom-N (in %)')\n",
    "plt.ylabel('Size of intersection (Number of models)')\n",
    "#plt.axvline(x=10, color='red')\n",
    "#plt.axvline(x=25, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Relative Bottom-N%:  crossing single regimes (comparing 4 with 4, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'test_accuracy'\n",
    "\n",
    "size_inter_all_rel = dict()\n",
    "\n",
    "all_cifar_regimes = [all_data_4_cf10, all_data_12_cf10, all_data_36_cf10, all_data_108_cf10]\n",
    "\n",
    "for cf_10_ri, ri in zip(all_cifar_regimes, [4, 12, 36, 108]):\n",
    "    \n",
    "    sorted_by_key = sorted(cf_10_ri, key= lambda triplet: triplet[2][key]) \n",
    "    size_inter_all_rel[ri] = list()\n",
    "    \n",
    "    for N in range(1, 101):        \n",
    "\n",
    "        key = 'test_accuracy'\n",
    "        top_n_idx = len(sorted_by_key) * N/100\n",
    "        top_n_idx = round(top_n_idx)\n",
    "\n",
    "        top_n_r_cf10 = sorted_by_key[:top_n_idx]\n",
    "\n",
    "        top_n_ri_lcz42 = top_n(mean_perf_half, N=N, regime=ri, key='kappaCohen_test')\n",
    "\n",
    "        model_min = top_n_r_cf10[0]\n",
    "        model_max = top_n_r_cf10[len(top_n_r_cf10)-1]\n",
    "\n",
    "        min_ri_test_acc = min(model_min[2]['test_accuracy'], model_max[2]['test_accuracy'])\n",
    "        max_ri_test_acc = max(model_min[2]['test_accuracy'], model_max[2]['test_accuracy'])\n",
    "\n",
    "\n",
    "        cross_cf10_lcz42 = []\n",
    "        for m, o, cell in top_n_ri_lcz42:\n",
    "            # Query an Inception-like cell from the dataset.\n",
    "            cell = api.ModelSpec(\n",
    "              matrix= m.astype(int),\n",
    "              # Operations at the vertices of the module, matches order of matrix.\n",
    "              ops= o) #[INPUT, CONV1X1, CONV3X3, CONV3X3, CONV3X3, MAXPOOL3X3, OUTPUT])\n",
    "\n",
    "            data = nasbench.query(cell, epochs=ri)\n",
    "            if data['test_accuracy'] >= min_ri_test_acc and data['test_accuracy'] <= max_ri_test_acc:\n",
    "                cross_cf10_lcz42.append((m, o, data))\n",
    "        size_inter_all_rel[ri].append(100 * len(cross_cf10_lcz42) / len(top_n_ri_lcz42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Robustness across datasets: models remaining Top-N% for same regimes'\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.ylim(0, 100) #len(mean_perf_half))\n",
    "plt.xlim(0, 100)\n",
    "#plt.set_xticks(5)\n",
    "plt.plot(range(1, 101), size_inter_all_rel[4], label = \"Across: [4] epochs (Reference)\",)\n",
    "plt.plot(range(1, 101), size_inter_all_rel[12], label = \"Across: [12] epochs (Reference)\",)\n",
    "plt.plot(range(1, 101), size_inter_all_rel[36], label = \"Across: [36] epochs (Reference)\",)\n",
    "plt.plot(range(1, 101), size_inter_all_rel[108], label = \"Across: [108] epochs (Reference)\",)\n",
    "plt.title(label=title)\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Bottom-N (in %)')\n",
    "plt.ylabel('Size of intersection (%)')\n",
    "#plt.axvline(x=10, color='red')\n",
    "#plt.axvline(x=25, color='red')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
